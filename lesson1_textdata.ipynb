{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f67cc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¨ Config not found for parakeet. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/auto_docstring.py\n",
      "ðŸš¨ Config not found for parakeet. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/auto_docstring.py\n",
      "ðŸš¨ Config not found for parakeet. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/auto_docstring.py\n"
     ]
    }
   ],
   "source": [
    "import re, sys, os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from plum import dispatch\n",
    "import torch\n",
    "import torch_directml\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "from fastai.data.all import *\n",
    "import pandas as pd\n",
    "\n",
    "torch._logging.set_logs(all=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b302fbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DIRECTML FULL DEBUG LOG STARTED\n",
      "torch version: 2.4.1+cpu\n",
      "Device: privateuseone:0\n",
      "GPU: Radeon RX 560X\u0000\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Setup DirectML\n",
    "print(\"=\"*80)\n",
    "print(\"DIRECTML FULL DEBUG LOG STARTED\")\n",
    "print(f\"torch version: {torch_directml.torch.__version__}\")\n",
    "print(f\"Device: {torch_directml.device()}\")\n",
    "print(f\"GPU: {torch_directml.device_name(0)}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "dml = torch_directml.device()\n",
    "\n",
    "# Global monkey-patch for Normalize\n",
    "old_init = Normalize.__init__\n",
    "def new_init(self, mean, std, axes=(0,2,3)):\n",
    "    old_init(self, mean.to(dml), std.to(dml), axes=axes)\n",
    "Normalize.__init__ = new_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dacd059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 1. Monkey-patch TensorText to add truncate and show methods\n",
    "# =====================================================\n",
    "@patch\n",
    "def truncate(self: TensorText, n):\n",
    "    \"\"\"Truncate TensorText to n tokens\"\"\"\n",
    "    return type(self)(self[:n])\n",
    "\n",
    "@patch  \n",
    "def show(self: TensorText, ctx=None, **kwargs):\n",
    "    \"\"\"Show decoded text\"\"\"\n",
    "    # Get the tokenizer from kwargs or use a stored one\n",
    "    tokenizer = kwargs.get('tokenizer', getattr(self, '_tokenizer', None))\n",
    "    \n",
    "    if tokenizer is not None:\n",
    "        # Decode using HF tokenizer\n",
    "        text = tokenizer.decode(self.cpu().tolist(), skip_special_tokens=True)\n",
    "    else:\n",
    "        # Fallback: just show token IDs\n",
    "        text = str(self.cpu().tolist())\n",
    "    \n",
    "    if ctx is None:\n",
    "        print(text)\n",
    "        return text\n",
    "    return show_title(text, ctx=ctx, **kwargs)\n",
    "\n",
    "# =====================================================\n",
    "# 2. Simple Transform - just tokenize to input_ids\n",
    "# =====================================================\n",
    "class HFTokenize(Transform):\n",
    "    \"\"\"Transform that tokenizes text files using HuggingFace tokenizer\"\"\"\n",
    "    def __init__(self, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        # Store tokenizer globally for TensorText.show() to access\n",
    "        TensorText._hf_tokenizer = tokenizer\n",
    "    \n",
    "    def encodes(self, path: Path):\n",
    "        \"\"\"Read file and tokenize, returning TensorText with just input_ids\"\"\"\n",
    "        text = path.read_text(encoding='utf-8') if path.exists() else \"\"\n",
    "        \n",
    "        # Tokenize - get tensors directly from tokenizer\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation='longest_first',\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt'  # Return PyTorch tensors\n",
    "        )\n",
    "        \n",
    "        # Squeeze batch dimension [1, seq_len] -> [seq_len]\n",
    "        tensor_text = TensorText(encoding['input_ids'].squeeze(0))\n",
    "        # Attach tokenizer for later decoding\n",
    "        tensor_text._tokenizer = self.tokenizer\n",
    "        return tensor_text\n",
    "    \n",
    "    def decodes(self, o):\n",
    "        \"\"\"Keep as TensorText for show_batch compatibility\"\"\"\n",
    "        # Don't decode to string - keep as TensorText\n",
    "        # The actual text decoding happens in show() method\n",
    "        return o\n",
    "\n",
    "# =====================================================\n",
    "# 2. Callback that computes attention_mask on-the-fly\n",
    "# =====================================================\n",
    "class HFCallback(Callback):\n",
    "    \"\"\"\n",
    "    Computes attention_mask from padded input_ids and injects into model.\n",
    "    This is the ONLY place where HuggingFace-specific logic lives.\n",
    "    \"\"\"\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "    \n",
    "    def before_batch(self):\n",
    "        \"\"\"Compute attention_mask from input_ids before each forward pass\"\"\"\n",
    "        # Get input_ids from batch\n",
    "        xb = self.xb[0] if isinstance(self.xb, tuple) and len(self.xb) > 0 else self.xb\n",
    "        \n",
    "        # Compute attention_mask: 1 for real tokens, 0 for padding\n",
    "        attention_mask = (xb != self.pad_idx).long()\n",
    "        \n",
    "        # Inject into model for this forward pass\n",
    "        self.model._attention_mask = attention_mask\n",
    "\n",
    "# =====================================================\n",
    "# 3. Model wrapper that uses injected attention_mask\n",
    "# =====================================================\n",
    "class HFModelWrapper(Module):\n",
    "    \"\"\"Wrapper to adapt HF model to FastAI\"\"\"\n",
    "    def __init__(self, hf_model, pad_idx):\n",
    "        self.hf_model = hf_model\n",
    "        self.pad_idx = pad_idx\n",
    "        self._attention_mask = None\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        # Get attention_mask from callback (or compute default)\n",
    "        attention_mask = getattr(self, '_attention_mask', None)\n",
    "        if attention_mask is None:\n",
    "            attention_mask = (input_ids != self.pad_idx).long()\n",
    "        \n",
    "        # Clear after use (for next batch)\n",
    "        self._attention_mask = None\n",
    "        \n",
    "        # Forward pass with attention mask\n",
    "        outputs = self.hf_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        return outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc74957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at models\\models--haisongzhang--roberta-tiny-cased\\snapshots\\2e8caf4404987b8cb20fa4b22955f56940b2ebc6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Attempting to create safetensors variant\n",
      "Safetensors PR exists\n",
      "loading weights file model.safetensors from cache at models\\models--haisongzhang--roberta-tiny-cased\\snapshots\\bfd314bd7663eef65c83e57719c0d9f3c21aa631\\model.safetensors\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at haisongzhang/roberta-tiny-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file config.json from cache at C:\\Users\\Keshav\\.cache\\huggingface\\hub\\models--haisongzhang--roberta-tiny-cased\\snapshots\\2e8caf4404987b8cb20fa4b22955f56940b2ebc6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\Keshav\\.cache\\huggingface\\hub\\models--haisongzhang--roberta-tiny-cased\\snapshots\\2e8caf4404987b8cb20fa4b22955f56940b2ebc6\\vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\Keshav\\.cache\\huggingface\\hub\\models--haisongzhang--roberta-tiny-cased\\snapshots\\2e8caf4404987b8cb20fa4b22955f56940b2ebc6\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Keshav\\.cache\\huggingface\\hub\\models--haisongzhang--roberta-tiny-cased\\snapshots\\2e8caf4404987b8cb20fa4b22955f56940b2ebc6\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\Keshav\\.cache\\huggingface\\hub\\models--haisongzhang--roberta-tiny-cased\\snapshots\\2e8caf4404987b8cb20fa4b22955f56940b2ebc6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\Keshav\\.cache\\huggingface\\hub\\models--haisongzhang--roberta-tiny-cased\\snapshots\\2e8caf4404987b8cb20fa4b22955f56940b2ebc6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 5. Setup DataLoaders and Model\n",
    "# =====================================================\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model_cache_dir = Path(\"models\")\n",
    "hf_model = \"haisongzhang/roberta-tiny-cased\"\n",
    "\n",
    "# Load HF model and tokenizer\n",
    "hf_model_obj = AutoModelForSequenceClassification.from_pretrained(\n",
    "    hf_model, num_labels=2, cache_dir=model_cache_dir,\n",
    "    use_safetensors=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model)\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "704b566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = untar_data(URLs.IMDB)\n",
    "\n",
    "# Create DataBlock with HFTransform\n",
    "blocks = (\n",
    "    TransformBlock(\n",
    "        type_tfms=HFTokenize(tokenizer, max_length=512),\n",
    "        dls_kwargs={'before_batch': Pad_Chunk(seq_len=512, pad_idx=tokenizer.pad_token_id)}\n",
    "    ),\n",
    "    CategoryBlock\n",
    ")\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_items=get_text_files,\n",
    "    get_y=parent_label,\n",
    "    splitter=GrandparentSplitter(valid_name='test')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a622ffe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting items from C:\\Users\\Keshav\\.fastai\\data\\imdb\n",
      "Found 100002 items\n",
      "2 datasets of sizes 25000,25000\n",
      "Setting up Pipeline: HFTokenize\n",
      "Setting up Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
      "\n",
      "Setting up after_item: Pipeline: ToTensor\n",
      "Setting up before_batch: Pipeline: Pad_Chunk -- {'pad_idx': 0, 'pad_first': True, 'seq_len': 512}\n",
      "\n",
      "Setting up after_batch: Pipeline: \n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "dls = dblock.dataloaders(path, bs=1, device=dml, verbose=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "911caa5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cross - eyed is a very original and funny movie. i think adam jones brings a refreshing new set of eyes to the comedy genre and really reinvents it in a good way. this film is smart, concise, and consistently entertaining and funny. as a writer / director, jones exhibits complete control over his characters who are both absurd and lovable. the story is definitely something you haven't seen before which is good. it's unique and fun, and manages to work in visually fantastic elements as well as the long lost slapstick genre together to form a hearty comedy. &lt; br / &gt; &lt; br / &gt; a very promising first film.</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ce1d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LEARNER CREATED SUCCESSFULLY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 7. Create Learner with custom callback\n",
    "# =====================================================\n",
    "# Wrap the HF model\n",
    "model_wrapped = HFModelWrapper(hf_model_obj, tokenizer.pad_token_id)\n",
    "model_wrapped.to(dml)\n",
    "\n",
    "# Create learner\n",
    "learn = Learner(\n",
    "    dls, \n",
    "    model_wrapped,\n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    metrics=accuracy,\n",
    "    cbs=[HFCallback(pad_idx=tokenizer.pad_token_id)]\n",
    ").to_fp16(enabled=False)\n",
    "\n",
    "learn.to(dml)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LEARNER CREATED SUCCESSFULLY\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e093f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VERIFYING BATCH STRUCTURE\n",
      "================================================================================\n",
      "Batch shape: torch.Size([1, 512])\n",
      "Batch dtype: torch.int64\n",
      "First item type: <class 'fastai.text.data.TensorText'>\n",
      "Labels shape: torch.Size([1])\n",
      "Pad token ID: 0\n",
      "Sample tokens (first 20): TensorText([  101,  1103,  1825,  1150,  1724,  1103, 10140,  3189,  1104,\n",
      "             1142,  1940,  1116, 13830, 10517,  1933,  1538,  1129,  2272,\n",
      "             1106,  1103], device='privateuseone:0')\n",
      "Padding tokens in first sample: 352/512\n",
      "\n",
      "âœ“ Batch structure correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFYING BATCH STRUCTURE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    batch = dls.one_batch()\n",
    "    xb, yb = batch\n",
    "    \n",
    "    print(f\"Batch shape: {xb.shape}\")\n",
    "    print(f\"Batch dtype: {xb.dtype}\")\n",
    "    print(f\"First item type: {type(xb[0])}\")\n",
    "    print(f\"Labels shape: {yb.shape}\")\n",
    "    print(f\"Pad token ID: {tokenizer.pad_token_id}\")\n",
    "    print(f\"Sample tokens (first 20): {xb[0][:20]}\")\n",
    "    \n",
    "    # Show padding\n",
    "    pad_count = (xb[0] == tokenizer.pad_token_id).sum().item()\n",
    "    print(f\"Padding tokens in first sample: {pad_count}/{len(xb[0])}\")\n",
    "    \n",
    "    print(\"\\nâœ“ Batch structure correct!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâœ— Batch verification error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a8b464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.691856</td>\n",
       "      <td>0.693141</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4:39:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.695306</td>\n",
       "      <td>0.693142</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4:37:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "\n",
    "# Profile the training\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "learn.fine_tune(1, base_lr=4e-3)\n",
    "profiler.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a49b5451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1704328515 function calls (1564952522 primitive calls) in 33434.991 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 1063 to 30 due to restriction <30>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   506466    7.704    0.000 123800.188    0.244 C:\\Users\\Keshav\\.pyenv\\pyenv-win\\versions\\3.12.9\\Lib\\asyncio\\base_events.py:1922(_run_once)\n",
      "   506741    1.888    0.000 48105.548    0.095 C:\\Users\\Keshav\\.pyenv\\pyenv-win\\versions\\3.12.9\\Lib\\asyncio\\events.py:86(_run)\n",
      "      3/2    0.000    0.000 33436.142 16718.071 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\fastai\\learner.py:258(_do_fit)\n",
      "   100004    3.590    0.000 32926.898    0.329 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\fastai\\data\\load.py:125(__iter__)\n",
      " 12707876  117.812    0.000 25874.254    0.002 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\fastai\\torch_core.py:380(__torch_function__)\n",
      " 12707876  121.500    0.000 25450.263    0.002 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\torch\\_tensor.py:1415(__torch_function__)\n",
      "   506466    8.317    0.000 21070.697    0.042 C:\\Users\\Keshav\\.pyenv\\pyenv-win\\versions\\3.12.9\\Lib\\selectors.py:319(select)\n",
      "   506466    3.802    0.000 19381.030    0.038 C:\\Users\\Keshav\\.pyenv\\pyenv-win\\versions\\3.12.9\\Lib\\selectors.py:313(_select)\n",
      "   100000   20.623    0.000 19351.727    0.194 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\fastai\\learner.py:223(_do_one_batch)\n",
      "   506741    1.380    0.000 16863.408    0.033 {method 'run' of '_contextvars.Context' objects}\n",
      "    50000    0.539    0.000 14498.555    0.290 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\fastai\\learner.py:218(_do_grad_opt)\n",
      "  1676164   15.096    0.000 11922.191    0.007 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\torch\\overrides.py:1583(handle_torch_function)\n",
      "  4200112   18.959    0.000 11480.256    0.003 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\fastai\\callback\\core.py:56(__call__)\n",
      "    50000    0.231    0.000 11339.129    0.227 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\fastai\\learner.py:215(_backward)\n",
      "100000/50000    1.209    0.000 11338.898    0.227 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\torch\\_tensor.py:465(backward)\n",
      "    50000    0.767    0.000 11201.290    0.224 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\torch\\autograd\\__init__.py:183(backward)\n",
      "    50000    0.725    0.000 11195.802    0.224 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\torch\\autograd\\graph.py:764(_engine_run_backward)\n",
      "    50000 11194.967    0.224 11194.967    0.224 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "   100000    2.332    0.000 10672.443    0.107 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\fastai\\learner.py:570(after_batch)\n",
      "850000/450000    6.713    0.000 10495.638    0.023 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\fastai\\torch_core.py:222(apply)\n",
      "   150000    0.741    0.000 10405.001    0.069 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\fastai\\torch_core.py:239(to_detach)\n",
      "   150000    0.856    0.000 10398.686    0.069 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\fastai\\torch_core.py:241(_inner)\n",
      "300000/150000 10289.572    0.034 10308.287    0.069 {method 'cpu' of 'torch._C.TensorBase' objects}\n",
      "        2    0.000    0.000 10204.041 5102.020 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\fastai\\learner.py:245(_do_epoch_train)\n",
      "   425487    1.433    0.000 9418.586    0.022 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\tornado\\platform\\asyncio.py:206(_handle_events)\n",
      "   500052    4.671    0.000 9022.141    0.018 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\zmq\\eventloop\\zmqstream.py:573(_handle_events)\n",
      "   100004    2.151    0.000 8448.644    0.084 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:625(__next__)\n",
      "    50000    1.885    0.000 8010.920    0.160 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\fastai\\learner.py:521(accumulate)\n",
      "   500052    3.017    0.000 7721.793    0.015 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\zmq\\eventloop\\zmqstream.py:614(_handle_recv)\n",
      "   100004    0.732    0.000 5960.801    0.060 f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\torch\\autograd\\profiler.py:687(__enter__)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get top bottlenecks\n",
    "s = StringIO()\n",
    "ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')\n",
    "ps.print_stats(30)  # Top 30 functions\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b4e68a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Projects\\VsCodium\\Python\\2025\\GenAI\\11\\.venv3_12_9\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('pos', TensorText(1), TensorText([0.4962, 0.5038]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = Path(\"test_reviews/test_1.txt\")\n",
    "learn.predict(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4557f0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv3_12_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
